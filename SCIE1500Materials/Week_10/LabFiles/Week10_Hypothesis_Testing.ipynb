{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 10 Lab: Hypothesis Testing\n",
    "\n",
    "## Making Decisions Under Uncertainty\n",
    "\n",
    "**SCIE1500 - Analytical Methods for Scientists**\n",
    "\n",
    "---\n",
    "\n",
    "### Learning Objectives\n",
    "\n",
    "By the end of this lab, you will be able to:\n",
    "\n",
    "1. Calculate expected values and variances from probability distributions\n",
    "2. Formulate null and alternative hypotheses correctly\n",
    "3. Distinguish between one-tailed and two-tailed tests (**CRITICAL for exam Q35**)\n",
    "4. Calculate p-values using `binom.pmf` and `binomtest`\n",
    "5. Make statistical decisions at the 5% significance level\n",
    "6. Visualize rejection regions and p-values\n",
    "\n",
    "---\n",
    "\n",
    "### What to Submit\n",
    "\n",
    "1. **During Lab:** Complete **Exercise A** and show your results to your lab demonstrator\n",
    "2. **By Due Date:** Upload screenshots of completed **Exercises A, B**, and **C** (practice quiz answers)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SETUP: Run this cell first ===\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import binom, binomtest\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_rows', None)\n",
    "np.set_printoptions(precision=5)\n",
    "\n",
    "print(\"‚úì All packages loaded successfully!\")\n",
    "print(\"\\nThis week: Hypothesis Testing ‚Äî Making Decisions Under Uncertainty\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part A: Review of Random Variables\n",
    "\n",
    "### A.1 Expected Value\n",
    "\n",
    "The **expected value** (mean) of a discrete random variable is:\n",
    "\n",
    "$$\\boxed{E[X] = \\sum_{x} x \\cdot P(X = x)}$$\n",
    "\n",
    "This is the probability-weighted average of all possible values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Expected Value Calculation (Q33 Style)\n",
    "# Given probability distribution:\n",
    "# X:    0    3    4    6\n",
    "# P(X): 0.2  0.4  0.3  0.1\n",
    "\n",
    "x_values = np.array([0, 3, 4, 6])\n",
    "probabilities = np.array([0.2, 0.4, 0.3, 0.1])\n",
    "\n",
    "# Verify probabilities sum to 1\n",
    "print(f\"Sum of probabilities: {probabilities.sum()} (should be 1.0)\")\n",
    "\n",
    "# Calculate E[X]\n",
    "expected_value = np.sum(x_values * probabilities)\n",
    "\n",
    "print(f\"\\nE[X] = {x_values[0]}√ó{probabilities[0]} + {x_values[1]}√ó{probabilities[1]} + {x_values[2]}√ó{probabilities[2]} + {x_values[3]}√ó{probabilities[3]}\")\n",
    "print(f\"E[X] = {x_values[0]*probabilities[0]} + {x_values[1]*probabilities[1]} + {x_values[2]*probabilities[2]} + {x_values[3]*probabilities[3]}\")\n",
    "print(f\"E[X] = {expected_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A.2 Binomial Distribution Review\n",
    "\n",
    "For $X \\sim \\text{Binomial}(n, p)$:\n",
    "\n",
    "$$P(X = k) = \\binom{n}{k} p^k (1-p)^{n-k}$$\n",
    "\n",
    "**Key properties:**\n",
    "- $E[X] = np$\n",
    "- $\\text{Var}(X) = np(1-p)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binomial distribution example: 12 coin tosses\n",
    "n = 12\n",
    "p = 0.5\n",
    "\n",
    "k_values = np.arange(0, n + 1)\n",
    "probabilities = binom.pmf(k_values, n, p)\n",
    "\n",
    "# Create a table\n",
    "df = pd.DataFrame({\n",
    "    'k (successes)': k_values,\n",
    "    'P(X = k)': np.round(probabilities, 5)\n",
    "})\n",
    "print(f\"Binomial Distribution: X ~ Binomial({n}, {p})\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# Mean and Variance\n",
    "print(f\"\\nE[X] = np = {n}√ó{p} = {n*p}\")\n",
    "print(f\"Var(X) = np(1-p) = {n}√ó{p}√ó{1-p} = {n*p*(1-p)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the binomial distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(k_values, probabilities, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "plt.axvline(x=n*p, color='red', linestyle='--', linewidth=2, label=f'Mean = {n*p}')\n",
    "plt.xlabel('k (Number of Successes)', fontsize=12)\n",
    "plt.ylabel('P(X = k)', fontsize=12)\n",
    "plt.title(f'Binomial Distribution: X ~ Binomial({n}, {p})', fontsize=14)\n",
    "plt.xticks(k_values)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part B: Introduction to Hypothesis Testing\n",
    "\n",
    "### B.1 The Big Picture\n",
    "\n",
    "In Week 9, we calculated probabilities. Now we ask: **Can we use data to test claims?**\n",
    "\n",
    "**Example:** You toss a coin 12 times and get 10 heads. Is the coin fair ($p = 0.5$)?\n",
    "\n",
    "### B.2 The p-Value\n",
    "\n",
    "The **p-value** answers: *How likely is it to observe data this extreme (or more extreme) if the hypothesis is true?*\n",
    "\n",
    "$$\\boxed{\\text{p-value} = P(\\text{data this extreme or more} \\;|\\; H_0 \\text{ is true})}$$\n",
    "\n",
    "### B.3 The Decision Rule\n",
    "\n",
    "- If **p-value < 0.05**: Reject $H_0$ (statistically significant)\n",
    "- If **p-value ‚â• 0.05**: Fail to reject $H_0$ (not enough evidence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part C: Calculating p-Values\n",
    "\n",
    "### C.1 Using `binom.pmf` (Manual Method)\n",
    "\n",
    "**Scenario:** You observed 10 heads out of 12 tosses. Is the coin fair?\n",
    "\n",
    "If $p = 0.5$ (fair coin), how likely is getting 10+ heads?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate p-value manually using binom.pmf\n",
    "n = 12\n",
    "p_null = 0.5  # Null hypothesis: fair coin\n",
    "observed_k = 10\n",
    "\n",
    "# Calculate all probabilities\n",
    "k_values = np.arange(0, n + 1)\n",
    "probabilities = binom.pmf(k_values, n, p_null)\n",
    "\n",
    "# Create table\n",
    "df = pd.DataFrame({'k': k_values, 'P(X=k)': np.round(probabilities, 5)})\n",
    "print(\"Binomial probabilities under H‚ÇÄ: p = 0.5\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# p-value for ONE-TAILED test (upper): P(X >= 10)\n",
    "p_value_upper = sum(probabilities[k_values >= observed_k])\n",
    "print(f\"\\nP(X ‚â• {observed_k}) = {p_value_upper:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For TWO-TAILED test, include equally extreme values from BOTH tails\n",
    "# If 10 heads is extreme (deviation of 4 from mean of 6), \n",
    "# then 2 heads is equally extreme (also deviation of 4)\n",
    "\n",
    "p_value_lower = sum(probabilities[k_values <= 2])  # P(X <= 2)\n",
    "p_value_two_tailed = p_value_upper + p_value_lower\n",
    "\n",
    "print(f\"One-tailed (upper): P(X ‚â• {observed_k}) = {p_value_upper:.5f}\")\n",
    "print(f\"One-tailed (lower): P(X ‚â§ 2) = {p_value_lower:.5f}\")\n",
    "print(f\"Two-tailed: {p_value_upper:.5f} + {p_value_lower:.5f} = {p_value_two_tailed:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.2 Using `binomtest` (Recommended Method)\n",
    "\n",
    "The `binomtest` function calculates p-values directly.\n",
    "\n",
    "**Syntax:** `binomtest(k, n, p, alternative)`\n",
    "\n",
    "| Alternative | Hypotheses | Use When |\n",
    "|-------------|------------|----------|\n",
    "| `'greater'` | $H_0: p \\le p_0$ vs $H_a: p > p_0$ | Testing if parameter is **greater** |\n",
    "| `'less'` | $H_0: p \\ge p_0$ vs $H_a: p < p_0$ | Testing if parameter is **less** |\n",
    "| `'two-sided'` | $H_0: p = p_0$ vs $H_a: p \\ne p_0$ | Testing if parameter is **different** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using binomtest\n",
    "n = 12\n",
    "observed_k = 10\n",
    "p_null = 0.5\n",
    "\n",
    "print(\"Using scipy.stats.binomtest()\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# One-tailed test (upper): Is coin biased toward heads?\n",
    "result_greater = binomtest(k=observed_k, n=n, p=p_null, alternative='greater')\n",
    "print(f\"\\nOne-tailed test (H‚Çê: p > 0.5):\")\n",
    "print(f\"  p-value = {result_greater.pvalue:.5f}\")\n",
    "\n",
    "# Two-tailed test: Is coin biased (either direction)?\n",
    "result_two_sided = binomtest(k=observed_k, n=n, p=p_null, alternative='two-sided')\n",
    "print(f\"\\nTwo-tailed test (H‚Çê: p ‚â† 0.5):\")\n",
    "print(f\"  p-value = {result_two_sided.pvalue:.5f}\")\n",
    "\n",
    "# Decision\n",
    "alpha = 0.05\n",
    "print(f\"\\nDecision at Œ± = {alpha}:\")\n",
    "print(f\"  One-tailed: {'REJECT H‚ÇÄ' if result_greater.pvalue < alpha else 'Fail to reject H‚ÇÄ'}\")\n",
    "print(f\"  Two-tailed: {'REJECT H‚ÇÄ' if result_two_sided.pvalue < alpha else 'Fail to reject H‚ÇÄ'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C.3 Visualizing the p-Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize p-value for one-tailed test (upper)\n",
    "n = 12\n",
    "p_null = 0.5\n",
    "observed_k = 10\n",
    "\n",
    "k_values = np.arange(0, n + 1)\n",
    "probabilities = binom.pmf(k_values, n, p_null)\n",
    "\n",
    "# Color bars: red for p-value region (k >= observed)\n",
    "colors = ['coral' if k >= observed_k else 'steelblue' for k in k_values]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(k_values, probabilities, color=colors, edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Add annotations\n",
    "p_value = sum(probabilities[k_values >= observed_k])\n",
    "plt.axvline(x=observed_k - 0.5, color='red', linestyle='--', alpha=0.7)\n",
    "\n",
    "plt.text(0.02, 0.95, f'p-value = P(X ‚â• {observed_k}) = {p_value:.4f}',\n",
    "         transform=plt.gca().transAxes, fontsize=12,\n",
    "         bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
    "\n",
    "plt.xlabel('k (Number of Heads)', fontsize=12)\n",
    "plt.ylabel('P(X = k)', fontsize=12)\n",
    "plt.title('One-Tailed Test: p-value = P(X ‚â• 10) under H‚ÇÄ: p = 0.5\\n(Red bars = p-value region)', fontsize=14)\n",
    "plt.xticks(k_values)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Legend\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='coral', label='p-value region'),\n",
    "                   Patch(facecolor='steelblue', label='Not in p-value')]\n",
    "plt.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part D: The Four Steps of Hypothesis Testing\n",
    "\n",
    "### D.1 The Framework\n",
    "\n",
    "Every hypothesis test has four components:\n",
    "\n",
    "1. **Null Hypothesis ($H_0$):** The \"status quo\" claim we want to test\n",
    "2. **Alternative Hypothesis ($H_a$):** What we suspect might be true\n",
    "3. **Test Statistic:** A numerical summary of the sample data\n",
    "4. **Decision Rule:** When to reject $H_0$ (based on significance level $\\alpha$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part E: One-Tailed vs Two-Tailed Tests\n",
    "\n",
    "### ‚ö†Ô∏è CRITICAL FOR EXAM Q35 ‚ö†Ô∏è\n",
    "\n",
    "The choice between one-tailed and two-tailed tests depends on the **research question**.\n",
    "\n",
    "| Test Type | Hypotheses | Use When |\n",
    "|-----------|------------|----------|\n",
    "| **One-tailed (upper)** | $H_0: p \\le p_0$ vs $H_a: p > p_0$ | \"Is it **greater** than...?\" |\n",
    "| **One-tailed (lower)** | $H_0: p \\ge p_0$ vs $H_a: p < p_0$ | \"Is it **less** than...?\" |\n",
    "| **Two-tailed** | $H_0: p = p_0$ vs $H_a: p \\ne p_0$ | \"Is it **different** from...?\" |\n",
    "\n",
    "### E.1 Example: Party Support (One-Tailed Test)\n",
    "\n",
    "**Problem:** A party leader claims support has **increased** from the previous election's 40%. A survey of 20 people finds 10 supporters. Test this claim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-tailed test: Has support INCREASED from 40%?\n",
    "print(\"=\"*60)\n",
    "print(\"ONE-TAILED TEST: Has party support INCREASED from 40%?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n = 20\n",
    "observed_k = 10\n",
    "p_null = 0.40\n",
    "\n",
    "print(f\"\\nData: {observed_k} supporters out of {n} surveyed\")\n",
    "print(f\"Sample proportion: pÃÇ = {observed_k}/{n} = {observed_k/n}\")\n",
    "\n",
    "# Step 1: Hypotheses\n",
    "print(f\"\\n--- Step 1: Hypotheses ---\")\n",
    "print(f\"H‚ÇÄ: p ‚â§ 0.40 (support has NOT increased)\")\n",
    "print(f\"H‚Çê: p > 0.40 (support HAS increased)\")\n",
    "\n",
    "# Step 2: Test statistic\n",
    "print(f\"\\n--- Step 2: Test Statistic ---\")\n",
    "p_hat = observed_k / n\n",
    "print(f\"pÃÇ = {observed_k}/{n} = {p_hat}\")\n",
    "\n",
    "# Step 3: p-value\n",
    "print(f\"\\n--- Step 3: Calculate p-value ---\")\n",
    "result = binomtest(k=observed_k, n=n, p=p_null, alternative='greater')\n",
    "print(f\"p-value = P(X ‚â• {observed_k} | p = 0.40) = {result.pvalue:.5f}\")\n",
    "\n",
    "# Step 4: Decision\n",
    "print(f\"\\n--- Step 4: Decision (Œ± = 0.05) ---\")\n",
    "if result.pvalue < 0.05:\n",
    "    print(f\"Since {result.pvalue:.4f} < 0.05, REJECT H‚ÇÄ\")\n",
    "    print(\"Conclusion: Evidence supports that support has increased.\")\n",
    "else:\n",
    "    print(f\"Since {result.pvalue:.4f} ‚â• 0.05, FAIL TO REJECT H‚ÇÄ\")\n",
    "    print(\"Conclusion: Insufficient evidence that support has increased.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E.2 Finding the Rejection Region\n",
    "\n",
    "Instead of calculating a p-value for each observation, we can find the **critical value** ‚Äî the boundary of the rejection region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the critical value (rejection region boundary)\n",
    "n = 20\n",
    "p_null = 0.40\n",
    "alpha = 0.05\n",
    "\n",
    "print(f\"Finding Critical Value for One-Tailed Test (Upper)\")\n",
    "print(f\"H‚ÇÄ: p ‚â§ {p_null} vs H‚Çê: p > {p_null}\")\n",
    "print(f\"n = {n}, Œ± = {alpha}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\n  k    P(X ‚â• k)    Reject H‚ÇÄ?\")\n",
    "print(\"-\"*35)\n",
    "\n",
    "critical_value = None\n",
    "for k in range(8, 16):  # Check relevant range\n",
    "    result = binomtest(k=k, n=n, p=p_null, alternative='greater')\n",
    "    reject = \"YES\" if result.pvalue < alpha else \"NO\"\n",
    "    marker = \" ‚Üê Critical value\" if result.pvalue < alpha and critical_value is None else \"\"\n",
    "    if result.pvalue < alpha and critical_value is None:\n",
    "        critical_value = k\n",
    "    print(f\"  {k}    {result.pvalue:.5f}     {reject}{marker}\")\n",
    "\n",
    "print(f\"\\nCritical value: k* = {critical_value}\")\n",
    "print(f\"Rule: Reject H‚ÇÄ if observed successes ‚â• {critical_value}\")\n",
    "print(f\"      (equivalently, if pÃÇ ‚â• {critical_value/n})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize rejection region\n",
    "n = 20\n",
    "p_null = 0.40\n",
    "observed_k = 10\n",
    "critical_k = 13\n",
    "\n",
    "k_values = np.arange(0, n + 1)\n",
    "probabilities = binom.pmf(k_values, n, p_null)\n",
    "\n",
    "# Color: red for rejection region, highlight observed\n",
    "colors = []\n",
    "for k in k_values:\n",
    "    if k >= critical_k:\n",
    "        colors.append('coral')  # Rejection region\n",
    "    elif k == observed_k:\n",
    "        colors.append('gold')  # Observed value\n",
    "    else:\n",
    "        colors.append('steelblue')\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(k_values, probabilities, color=colors, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(x=critical_k - 0.5, color='red', linestyle='--', linewidth=2, label=f'Critical value k* = {critical_k}')\n",
    "plt.axvline(x=n*p_null, color='green', linestyle='-', linewidth=2, label=f'Expected = {n*p_null}')\n",
    "\n",
    "plt.xlabel('k (Number of Supporters)', fontsize=12)\n",
    "plt.ylabel('P(X = k) under H‚ÇÄ: p = 0.40', fontsize=12)\n",
    "plt.title(f'Rejection Region for One-Tailed Test\\nReject H‚ÇÄ if k ‚â• {critical_k}; Observed k = {observed_k} (NOT in rejection region)', fontsize=13)\n",
    "plt.legend()\n",
    "plt.xticks(k_values)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Legend for colors\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='coral', label='Rejection region'),\n",
    "                   Patch(facecolor='gold', label=f'Observed (k={observed_k})'),\n",
    "                   Patch(facecolor='steelblue', label='Acceptance region')]\n",
    "plt.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E.3 Two-Tailed Test Example\n",
    "\n",
    "**Problem:** We want to test if support has **changed** (up OR down) from 40%. Same data: 10 supporters out of 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-tailed test: Has support CHANGED from 40%?\n",
    "print(\"=\"*60)\n",
    "print(\"TWO-TAILED TEST: Has party support CHANGED from 40%?\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "n = 20\n",
    "observed_k = 10\n",
    "p_null = 0.40\n",
    "\n",
    "# Hypotheses\n",
    "print(f\"\\nH‚ÇÄ: p = 0.40 (support is unchanged)\")\n",
    "print(f\"H‚Çê: p ‚â† 0.40 (support has changed)\")\n",
    "\n",
    "# p-value\n",
    "result = binomtest(k=observed_k, n=n, p=p_null, alternative='two-sided')\n",
    "print(f\"\\np-value = {result.pvalue:.5f}\")\n",
    "\n",
    "# Decision\n",
    "if result.pvalue < 0.05:\n",
    "    print(f\"Since {result.pvalue:.4f} < 0.05, REJECT H‚ÇÄ\")\n",
    "else:\n",
    "    print(f\"Since {result.pvalue:.4f} ‚â• 0.05, FAIL TO REJECT H‚ÇÄ\")\n",
    "    print(\"Conclusion: Insufficient evidence that support has changed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize two-tailed test\n",
    "n = 20\n",
    "p_null = 0.40\n",
    "observed_k = 10\n",
    "\n",
    "k_values = np.arange(0, n + 1)\n",
    "probabilities = binom.pmf(k_values, n, p_null)\n",
    "prob_observed = binom.pmf(observed_k, n, p_null)\n",
    "\n",
    "# For two-tailed: color bars with P(X=k) <= P(X=observed) as extreme\n",
    "eps = 1e-10\n",
    "colors = ['coral' if prob <= prob_observed + eps else 'steelblue' for prob in probabilities]\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.bar(k_values, probabilities, color=colors, edgecolor='black', alpha=0.7)\n",
    "plt.axhline(y=prob_observed, color='red', linestyle='--', alpha=0.7, label=f'P(X={observed_k})')\n",
    "\n",
    "# p-value\n",
    "p_value = sum(p for p in probabilities if p <= prob_observed + eps)\n",
    "plt.text(0.02, 0.95, f'p-value = {p_value:.4f}',\n",
    "         transform=plt.gca().transAxes, fontsize=12,\n",
    "         bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
    "\n",
    "plt.xlabel('k (Number of Supporters)', fontsize=12)\n",
    "plt.ylabel('P(X = k)', fontsize=12)\n",
    "plt.title('Two-Tailed Test: p-value includes both tails\\n(Red bars = values as extreme or more extreme than observed)', fontsize=13)\n",
    "plt.xticks(k_values)\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E.4 Comparing One-Tailed vs Two-Tailed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side-by-side comparison\n",
    "n = 20\n",
    "p_null = 0.5\n",
    "observed = 14\n",
    "\n",
    "k_values = np.arange(0, n + 1)\n",
    "probabilities = binom.pmf(k_values, n, p_null)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# One-tailed test (upper)\n",
    "colors_one = ['coral' if k >= observed else 'steelblue' for k in k_values]\n",
    "axes[0].bar(k_values, probabilities, color=colors_one, edgecolor='black', alpha=0.7)\n",
    "p_value_one = binomtest(k=observed, n=n, p=p_null, alternative='greater').pvalue\n",
    "axes[0].set_title(f'One-Tailed Test (H‚Çê: p > 0.5)\\np-value = {p_value_one:.4f}', fontsize=12)\n",
    "axes[0].set_xlabel('k')\n",
    "axes[0].set_ylabel('P(X = k)')\n",
    "axes[0].axvline(x=n*p_null, color='green', linestyle='--', label=f'Mean = {n*p_null}')\n",
    "\n",
    "# Two-tailed test\n",
    "deviation = abs(observed - n*p_null)\n",
    "lower_extreme = int(n*p_null - deviation)\n",
    "colors_two = ['coral' if (k >= observed or k <= lower_extreme) else 'steelblue' for k in k_values]\n",
    "axes[1].bar(k_values, probabilities, color=colors_two, edgecolor='black', alpha=0.7)\n",
    "p_value_two = binomtest(k=observed, n=n, p=p_null, alternative='two-sided').pvalue\n",
    "axes[1].set_title(f'Two-Tailed Test (H‚Çê: p ‚â† 0.5)\\np-value = {p_value_two:.4f}', fontsize=12)\n",
    "axes[1].set_xlabel('k')\n",
    "axes[1].set_ylabel('P(X = k)')\n",
    "axes[1].axvline(x=n*p_null, color='green', linestyle='--', label=f'Mean = {n*p_null}')\n",
    "\n",
    "fig.suptitle(f'Observed: {observed} successes out of {n}', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Summary for observed = {observed}, n = {n}, p‚ÇÄ = {p_null}:\")\n",
    "print(f\"  One-tailed p-value: {p_value_one:.4f} ‚Üí {'REJECT' if p_value_one < 0.05 else 'Fail to reject'} at Œ± = 0.05\")\n",
    "print(f\"  Two-tailed p-value: {p_value_two:.4f} ‚Üí {'REJECT' if p_value_two < 0.05 else 'Fail to reject'} at Œ± = 0.05\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part F: Q35 Exam Question ‚Äî New Virus Variant\n",
    "\n",
    "### ‚ö†Ô∏è THIS IS CRITICAL FOR THE EXAM ‚ö†Ô∏è\n",
    "\n",
    "**Scenario:** Health experts suspect a new virus variant is **more infectious** than the old one (which had $p = 0.50$ transmission rate). Out of 11 contacts, 9 resulted in infections.\n",
    "\n",
    "**Question:** Is this evidence that the new variant is more infectious?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q35: Is the new variant MORE infectious?\n",
    "print(\"=\"*70)\n",
    "print(\"Q35 EXAM QUESTION: Is the new variant MORE infectious?\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Given data\n",
    "n = 11\n",
    "observed_infections = 9\n",
    "p_old = 0.50\n",
    "\n",
    "print(f\"\\nData: {observed_infections} infections out of {n} contacts\")\n",
    "print(f\"Old variant rate: p = {p_old}\")\n",
    "print(f\"Question: Is the new variant MORE infectious?\")\n",
    "\n",
    "# The CORRECT approach: One-tailed test\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"‚úì CORRECT APPROACH: One-tailed test (because we ask 'MORE infectious')\")\n",
    "print(\"-\"*70)\n",
    "print(\"H‚ÇÄ: p ‚â§ 0.50 (new variant is NOT more infectious)\")\n",
    "print(\"H‚Çê: p > 0.50 (new variant IS more infectious)\")\n",
    "\n",
    "result_one_tailed = binomtest(k=observed_infections, n=n, p=p_old, alternative='greater')\n",
    "print(f\"\\np-value = P(X ‚â• {observed_infections} | p = 0.5) = {result_one_tailed.pvalue:.5f}\")\n",
    "print(f\"         = 67/2048 ‚âà 0.033\")\n",
    "\n",
    "print(f\"\\nSince {result_one_tailed.pvalue:.3f} < 0.05, REJECT H‚ÇÄ\")\n",
    "print(\"‚Üí Conclusion: Evidence supports that new variant IS more infectious\")\n",
    "\n",
    "# The WRONG approach: Two-tailed test\n",
    "print(\"\\n\" + \"-\"*70)\n",
    "print(\"‚úó INCORRECT APPROACH: Two-tailed test\")\n",
    "print(\"-\"*70)\n",
    "print(\"H‚ÇÄ: p = 0.50\")\n",
    "print(\"H‚Çê: p ‚â† 0.50\")\n",
    "\n",
    "result_two_tailed = binomtest(k=observed_infections, n=n, p=p_old, alternative='two-sided')\n",
    "print(f\"\\np-value = {result_two_tailed.pvalue:.5f}\")\n",
    "\n",
    "print(f\"\\nSince {result_two_tailed.pvalue:.3f} > 0.05, would FAIL TO REJECT H‚ÇÄ\")\n",
    "print(\"‚Üí This leads to the WRONG conclusion for this question!\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"KEY INSIGHT: Match the test type to the research question!\")\n",
    "print(\"  'More infectious' ‚Üí One-tailed (upper) test\")\n",
    "print(\"  'Different' ‚Üí Two-tailed test\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Q35\n",
    "n = 11\n",
    "p_null = 0.5\n",
    "observed_k = 9\n",
    "\n",
    "k_values = np.arange(0, n + 1)\n",
    "probabilities = binom.pmf(k_values, n, p_null)\n",
    "\n",
    "colors = ['coral' if k >= observed_k else 'steelblue' for k in k_values]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(k_values, probabilities, color=colors, edgecolor='black', alpha=0.7)\n",
    "\n",
    "# Annotations\n",
    "p_value = sum(probabilities[k_values >= observed_k])\n",
    "plt.annotate(f'Observed: k = {observed_k}', xy=(observed_k, probabilities[observed_k]),\n",
    "            xytext=(observed_k - 2, probabilities[observed_k] + 0.08),\n",
    "            arrowprops=dict(arrowstyle='->', color='red'),\n",
    "            fontsize=11, color='red', fontweight='bold')\n",
    "\n",
    "plt.text(0.02, 0.95, f'p-value = P(X ‚â• {observed_k}) = {p_value:.4f}',\n",
    "         transform=plt.gca().transAxes, fontsize=12,\n",
    "         bbox=dict(boxstyle='round', facecolor='lightyellow', alpha=0.8))\n",
    "\n",
    "plt.text(0.02, 0.85, 'Since 0.033 < 0.05: REJECT H‚ÇÄ',\n",
    "         transform=plt.gca().transAxes, fontsize=12,\n",
    "         bbox=dict(boxstyle='round', facecolor='lightcoral', alpha=0.8))\n",
    "\n",
    "plt.xlabel('k (Number of Infections)', fontsize=12)\n",
    "plt.ylabel('P(X = k) under H‚ÇÄ: p = 0.5', fontsize=12)\n",
    "plt.title('Q35: Testing if New Variant is MORE Infectious\\nOne-Tailed Test (H‚Çê: p > 0.5)', fontsize=14)\n",
    "plt.xticks(k_values)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='coral', label='p-value region (k ‚â• 9)'),\n",
    "                   Patch(facecolor='steelblue', label='Not in p-value')]\n",
    "plt.legend(handles=legend_elements, loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù STUDENT EXERCISE A (Show Demonstrator)\n",
    "\n",
    "### Two-Tailed Test with Larger Sample\n",
    "\n",
    "**Problem:** Repeat the party support test with a larger sample:\n",
    "- 200 people surveyed, 100 say they support the party\n",
    "- Test if support has **changed** from 40% (two-tailed)\n",
    "\n",
    "**Tasks:**\n",
    "1. State the null and alternative hypotheses\n",
    "2. Calculate the p-value using `binomtest`\n",
    "3. Make a decision at Œ± = 0.05\n",
    "4. Visualize the distribution and p-value region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE A: Two-tailed test with larger sample\n",
    "n = 200\n",
    "observed_k = 100\n",
    "p_null = 0.40\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# 1. State hypotheses (write in comments or print statements)\n",
    "# print(\"H‚ÇÄ: ...\")\n",
    "# print(\"H‚Çê: ...\")\n",
    "\n",
    "# 2. Calculate p-value\n",
    "# result = binomtest(k=..., n=..., p=..., alternative='two-sided')\n",
    "# print(f\"p-value = {result.pvalue}\")\n",
    "\n",
    "# 3. Make decision\n",
    "# if result.pvalue < 0.05:\n",
    "#     print(\"REJECT H‚ÇÄ\")\n",
    "# else:\n",
    "#     print(\"Fail to reject H‚ÇÄ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE A: Visualization\n",
    "# Create a bar plot showing the p-value region\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# Hint: Use k_values from around 60 to 120 for better visualization\n",
    "# k_values = np.arange(60, 121)\n",
    "# probabilities = binom.pmf(k_values, n, p_null)\n",
    "# ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù STUDENT EXERCISE B (Upload)\n",
    "\n",
    "### Virus Transmissibility Test\n",
    "\n",
    "**Problem:** A virus is known to have a transmission rate of 60% (p = 0.6). A new variant is claimed to be **more transmissible**. Out of 300 contact cases, 190 resulted in infections.\n",
    "\n",
    "**Conduct a formal hypothesis test:**\n",
    "1. What are your null and alternative hypotheses?\n",
    "2. What is your test statistic?\n",
    "3. What is the p-value?\n",
    "4. What is your conclusion/decision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCISE B: Your Answers\n",
    "\n",
    "**Null Hypothesis:**\n",
    "\n",
    "$H_0:$ _______________\n",
    "\n",
    "**Alternative Hypothesis:**\n",
    "\n",
    "$H_a:$ _______________\n",
    "\n",
    "**Test Statistic:**\n",
    "\n",
    "$\\hat{p} =$ _______________\n",
    "\n",
    "**Rejection Region:**\n",
    "\n",
    "_______________\n",
    "\n",
    "**DECISION:**\n",
    "\n",
    "_______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE B: Calculate p-value\n",
    "n = 300\n",
    "observed_k = 190\n",
    "p_null = 0.60\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# result = binomtest(k=..., n=..., p=..., alternative='...')\n",
    "# print(f\"p-value = {result.pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE B: Visualization\n",
    "# Create a plot showing the distribution and p-value region\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù STUDENT EXERCISE C (Upload)\n",
    "\n",
    "### Practice Quiz Answers\n",
    "\n",
    "Complete the **Probability practice quiz 2 (binomial distribution)(Week 10)** on LMS, then record your answers below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EXERCISE C: Practice Quiz Answers**\n",
    "\n",
    "Q1. Answer: _________________\n",
    "\n",
    "Q2. Answer: _________________\n",
    "\n",
    "Q3. Answer: _________________\n",
    "\n",
    "Q4. Answer: _________________\n",
    "\n",
    "Q5. Answer: _________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Key Concepts\n",
    "\n",
    "### The Four Steps of Hypothesis Testing\n",
    "\n",
    "1. **State hypotheses** ($H_0$ and $H_a$)\n",
    "2. **Calculate test statistic** (e.g., $\\hat{p} = k/n$)\n",
    "3. **Compute p-value**\n",
    "4. **Make decision** (reject or fail to reject $H_0$)\n",
    "\n",
    "### One-Tailed vs Two-Tailed Tests\n",
    "\n",
    "| Question Type | Test Type | `alternative` |\n",
    "|---------------|-----------|---------------|\n",
    "| \"Is it **greater** than...?\" | One-tailed (upper) | `'greater'` |\n",
    "| \"Is it **less** than...?\" | One-tailed (lower) | `'less'` |\n",
    "| \"Is it **different** from...?\" | Two-tailed | `'two-sided'` |\n",
    "\n",
    "### Key Python Functions\n",
    "\n",
    "```python\n",
    "from scipy.stats import binom, binomtest\n",
    "\n",
    "# Calculate P(X = k)\n",
    "binom.pmf(k, n, p)\n",
    "\n",
    "# Hypothesis test with p-value\n",
    "result = binomtest(k=observed, n=n, p=p_null, alternative='greater')\n",
    "result.pvalue  # The p-value\n",
    "```\n",
    "\n",
    "### Decision Rule\n",
    "\n",
    "At significance level $\\alpha = 0.05$:\n",
    "- **p-value < 0.05:** Reject $H_0$ (statistically significant)\n",
    "- **p-value ‚â• 0.05:** Fail to reject $H_0$ (not enough evidence)\n",
    "\n",
    "### Exam Tips (Q33, Q35)\n",
    "\n",
    "1. **Q33 (Expected Value):** $E[X] = \\sum x \\cdot P(X=x)$\n",
    "2. **Q35 (Hypothesis Testing):**\n",
    "   - \"More infectious\" ‚Üí **One-tailed test** (upper)\n",
    "   - \"Different\" ‚Üí Two-tailed test\n",
    "   - Match the test type to the research question!\n",
    "\n",
    "---\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "**Week 11** moves to **Trigonometric Functions**:\n",
    "- Modeling periodic phenomena (circadian rhythms, seasonal patterns)\n",
    "- Sine and cosine functions\n",
    "- Amplitude, period, and phase shift\n",
    "\n",
    "---\n",
    "\n",
    "*Hypothesis testing gives science its teeth ‚Äî it allows us to make rigorous decisions based on evidence, distinguishing real effects from statistical noise.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
